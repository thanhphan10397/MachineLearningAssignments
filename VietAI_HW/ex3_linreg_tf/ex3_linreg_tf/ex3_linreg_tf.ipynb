{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II/ Tìm nghiệm bài toán bằng `TensorFlow`\n",
    "\n",
    "##### 1) (Full) batch gradient descent: đưa toàn bộ X và Y vào để train:\n",
    "\n",
    "Với cách 1, do đưa toàn bộ batch vào nên gradient ở mỗi vòng lặp ổn định. Cách này được khuyến khích sử dụng khi hàm cost của mình biết rõ là convex (không có nhiều hơn 1 điểm tối ưu cục bộ). Tuy nhiên, đối với những hàm phức tạp, thì cách 1 có thể ko bao giờ đạt tối ưu toàn cục được.\n",
    "\n",
    "##### 2) Stochastic gradient descent: đưa từng cặp (x, y) trong data X, Y vào để train :\n",
    "\n",
    "Đối với cách 2, do mình đưa vào từng cặp nên gradient ở mỗi vòng lặp sẽ rất nhiễu (noisy). Chính vì sự nhiễu này mà có trong qúa trình học, nó có thể giúp mô hình vượt qua được các điểm tối ưu cục bộ. Stochastic = random, thể hiện cho sự nhiễu.\n",
    "##### 3) Mini-batch gradient descent: bốc 1 lượng nhiều hơn 1 mẫu từ X, Y để train.\n",
    "\n",
    "Cách 3 là sự kết hợp giữa 1 và 2, cũng là cách dùng nhiều nhất trong deep learning. Trong các bài tới sẽ đề cập sau.\n",
    "\n",
    "Còn về bài tập thì thực ra hàm error của mình hoàn toàn convex nên dùng cách 1 hay 2 đều được. Nhưng cách 2 sẽ lâu hơn. Bạn có thể sửa code lại để kiểm tra thử."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đưa dữ liệu vào"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected original features are ['NOX' 'RM']\n"
     ]
    }
   ],
   "source": [
    "from utils_function import load_Boston_housing_data\n",
    "import numpy as np\n",
    "raw_train_X, test_X, train_Y, test_Y = load_Boston_housing_data(feature_ind = [4,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nhập thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IMPORT\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import tensorflow as tf\n",
    "tf.__version__ # '2.x'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Khai báo biến"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.005\n",
    "training_epochs = 10000\n",
    "display_step = 1000\n",
    "n_samples, dimension = raw_train_X.shape\n",
    "batch_size = n_samples # Full Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bài 6. Khai báo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-0b3263634e6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Implement input and parameter for tensorflow.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_train_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# convert train_Y to tensor tf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# Implement input and parameter for tensorflow.\n",
    "train_X = tf.constant(raw_train_X, dtype=tf.float64)\n",
    "\n",
    "train_Y = tf.reshape(tensor=train_Y, shape=(-1, 1))\n",
    "train_Y = tf.constant(train_Y, dtype=tf.float64) # convert train_Y to tensor tf\n",
    "\n",
    "# Set model weights\n",
    "W = tf.Variable(np.random.normal(size=(dimension, 1)), trainable=True) # create weights variable to train\n",
    "b = tf.Variable(np.random.normal(size=(1, 1)), trainable=True)\n",
    "print(W)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bài 7. Xây dựng mô hình hồi quy tuyến tính"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION\n",
    "# TO_DO_6: implement a linear regression function\n",
    "def tf_lr_hypothesis(X, W, b):\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bài 8. Viết hàm cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION\n",
    "# TO_DO_7: implement a cost function\n",
    "def tf_mse_cost(Y_hat, Y):\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bài 9. Viết hàm train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create optimizer\n",
    "optimizer = tf.optimizers.SGD(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bài 10. Chạy chương trình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sinhtan/sinhenv/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch: 1000 | Cost: 26.647605539402317\n",
      "Epoch: 2000 | Cost: 24.727046852772094\n",
      "Epoch: 3000 | Cost: 23.26534940953925\n",
      "Epoch: 4000 | Cost: 22.152834262808618\n",
      "Epoch: 5000 | Cost: 21.30604075371691\n",
      "Epoch: 6000 | Cost: 20.66145902300803\n",
      "Epoch: 7000 | Cost: 20.170760773163888\n",
      "Epoch: 8000 | Cost: 19.797170122224315\n",
      "Epoch: 9000 | Cost: 19.51270200881538\n",
      "Epoch: 10000 | Cost: 19.296060759095315\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    with tf.GradientTape() as tape:\n",
    "        Y_hat = tf_lr_hypothesis(train_X, W, b) # apply linear regression function here\n",
    "        mse_cost = tf_mse_cost(Y_hat, train_Y) # apply mse cost here.\n",
    "    grads = tape.gradient(mse_cost, [W, b])\n",
    "    optimizer.apply_gradients(zip(grads, [W, b]))\n",
    "    if (epoch + 1) % display_step == 0:\n",
    "        print(\"Epoch:\", epoch + 1, \"| Cost:\", mse_cost.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Bài 11. Tạo các đặc tính mới (Feature Engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = raw_train_X[:,0].reshape((n_samples,1))\n",
    "X2 = raw_train_X[:,1].reshape((n_samples,1))\n",
    "X1_sqr = (X1**2).reshape((n_samples,1))\n",
    "sin_X2 = (np.sin(X2)).reshape((n_samples,1))\n",
    "X1X2 = (X1*X2).reshape((n_samples,1))\n",
    "# Create new input from new features\n",
    "new_train_X = np.concatenate((X1,X2,X1_sqr,sin_X2,X1X2),axis=1) # concatenate new features here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Bài 12. Khai báo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement input and parameter for tensorflow.\n",
    "new_train_X = tf.constant(new_train_X, dtype=tf.float64)\n",
    "_,new_dimension = new_train_X.shape\n",
    "optimizer = tf.optimizers.SGD(learning_rate=learning_rate)\n",
    "train_Y = tf.reshape(tensor=train_Y, shape=(-1, 1))\n",
    "train_Y = tf.constant(train_Y, dtype=tf.float64) # convert train_Y to tensor tf\n",
    "training_epochs = 10000\n",
    "display_step =1000\n",
    "# set model weight\n",
    "W = tf.Variable(np.random.normal(size=(new_dimension, 1)), trainable=True) # create weights variable to train\n",
    "b = tf.Variable(np.random.normal(size=(1, 1)), trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Bài 13. Chạy chương trình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1000 | Cost: 18.374142562614278\n",
      "Epoch: 2000 | Cost: 18.194247749466257\n",
      "Epoch: 3000 | Cost: 18.180264323830148\n",
      "Epoch: 4000 | Cost: 18.173748771743075\n",
      "Epoch: 5000 | Cost: 18.168026643717276\n",
      "Epoch: 6000 | Cost: 18.162418337296177\n",
      "Epoch: 7000 | Cost: 18.156845490573488\n",
      "Epoch: 8000 | Cost: 18.151298863447565\n",
      "Epoch: 9000 | Cost: 18.145777247771267\n",
      "Epoch: 10000 | Cost: 18.140280370654853\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    with tf.GradientTape() as tape:\n",
    "        Y_hat = tf_lr_hypothesis(new_train_X, W, b) # apply linear regression function here\n",
    "        mse_cost = tf_mse_cost(Y_hat, train_Y) # apply mse cost here\n",
    "    grads = tape.gradient(mse_cost, [W, b])\n",
    "    optimizer.apply_gradients(zip(grads, [W, b]))\n",
    "    if (epoch + 1) % display_step == 0:\n",
    "        print(\"Epoch:\", epoch + 1, \"| Cost:\", mse_cost.numpy())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
